---
layout: home
title: Home
---

Hi! I am a fifth year Ph.D. student at the <a href='https://filebox.ece.vt.edu/~parikh/CVL.html'>Computer Vision Lab, Georgia Tech</a>. My advisor is <a href='https://www.cc.gatech.edu/~parikh/'>Devi Parikh</a>. I am broadly interested in computer vision and machine learning. My research is supported by a Google PhD fellowship in Machine Perception, Speech Technology and Computer Vision. <span style="color:blue">I am graduating in 2018 and am on the job market.</span>

On the vision side, I am interested in problems in vision and language, learning common sense and visual reasoning. On the machine learning side, I am interested in developing tools for effective low-shot learning, generative models, bayesian deep learning and variational inference.

I also care about issues of how we evaluate our models, as we edge towards higher-level AI-complete tasks. In my first project in grad school, I worked on a (now popularly used) evaluation metric for image captioning called <a href="http://vrama91.github.io/cider/">CIDEr</a>. 

I have been fortunate to work with some great mentors and collaborators during grad school, including <a href="http://larryzitnick.org/">Larry Zitnick</a>,
<a href="http://www.cc.gatech.edu/~dbatra/index.html">Dhruv Batra</a>,
<a href="https://www.cs.ubc.ca/~murphyk/">Kevin Murphy</a>,
<a href="http://ai.stanford.edu/~gal/">Gal Chechik</a>, and <a href="http://bengio.abracadoudou.com/">Samy Bengio</a>.

In a previous life, I was an undergrad in ECE at IIIT-Hyderabad where I worked with <a href='http://www.iiit.ac.in/people/faculty/mkrishna'>K. Madhava Krishna</a> in Robotics. <a href='https://sites.google.com/site/vrama91/'>Here</a> is a link to my old website.

<hr/>

<h3>News</h3>
<ul>
<li> <b>[April, 2018]</b> I received the 2018 Google PhD Fellowship in Machine Perception, Speech Technology and Computer Vision!</li>
<li> <b>[March, 2018]</b> I will be interning at MSR Cambridge this summer, working on generative models of vision, language and action!</li>
<li> <b>[Feb, 2018]</b> Paper on learning grounded generative (image) models accepted to ICLR, 2018!</li>
<li> <b>[August, 2017]</b> I will be moving to Georgia Tech this Fall, following my advisor's move!</li>
<li> <b>[June, 2017]</b> Recognized as one of the outstanding reviewers at CVPR, 2017</li>
<li> <b>[June, 2017]</b> Paper on learning word embeddings grounded in sounds accepted as a short paper at EMNLP, 2017!</li>
<li> <b>[May, 2017]</b> I interned at Facebook AI Research (FAIR) in Summer, 2017, working with <a href='http://filebox.ece.vt.edu/~parikh'>Devi Parikh</a>, <a href="http://www.cc.gatech.edu/~dbatra/index.html">Dhruv Batra</a> and <a href="http://rohrbach.vision/">Marcus Rohrbach</a>!</li>
<li> <b>[March, 2017]</b> Two papers accepted to CVPR 2017 as Spotlight presentations! </li>
<li> <b>[Jan, 2017]</b> I interned at Google Research in Winter 2017, working with <a href="http://research.google.com/pubs/KevinMurphy.html">Kevin Murphy</a> on generative models for images!</li>
<li> <b>[May, 2016]</b> I interned at Google Research in Summer 2016, with <a href="http://ai.stanford.edu/~gal/">Gal Chechik</a> and <a href="http://bengio.abracadoudou.com/">Samy Bengio</a>!</li>
</ul>
<hr/>

<h3>Code</h3>
<ul>
<li> MSCOCO Caption Evaluation <a href="https://github.com/tylin/coco-caption"> code</a></li>
<li> <a href="https://github.com/vrama91/coco-caption">Codes</a> from MSCOCO Caption Evaluation for metrics (BLEU, ROUGE, CIDEr-D and METEOR), independent of the COCO annotations </li>
<li> Code for our CVPR'16 paper on <a href="https://github.com/satwikkottur/VisualWord2Vec">Learning Visually Grounded Word Embeddings</a></li>
<li> Code for our ICLR'18 paper on <a href="https://github.com/google/joint_vae">Generative Models of Visually Grounded Imagination</a></li>
</ul>	
<hr/>
If you like this layout/page, see <a href='demo-post'>this</a> to build your own using github+jekyll 
